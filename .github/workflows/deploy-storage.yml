name: Deploy to Azure Static Website

on:
  push:
    branches: ["main"]
  workflow_dispatch:

concurrency:
  group: storage-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    # Use whichever of these you’ve set in repo Settings → Secrets → Actions
    env:
      AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
      AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
      AZURE_STORAGE_SAS_TOKEN: ${{ secrets.AZURE_STORAGE_SAS_TOKEN }}  # If using SAS, store WITHOUT leading '?'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---- Repo snapshot artifact (keeps exact source for each deploy) ----
      - name: Create repo snapshot artifact
        run: |
          set -euo pipefail
          mkdir -p .artifacts
          echo "$GITHUB_SHA" > .artifacts/COMMIT.txt
          git ls-tree -r --name-only HEAD | sort > .artifacts/TREE.txt
          git archive -o .artifacts/repo-${GITHUB_SHA}.zip HEAD
          {
            echo "# Repo STATE"
            echo
            echo "- Commit: ${GITHUB_SHA}"
            echo "- Date: $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            echo
            echo "## Key files"
            for f in package.json next.config.js scripts/generateMedia.cjs pages/media.jsx app/media/page.jsx styles/globals.css app/globals.css .github/workflows/deploy-storage.yml public/site-data/videos.embeds.json; do
              if [ -f "$f" ]; then
                printf -- "- %s (%s)\n" "$f" "$(sha256sum "$f" | cut -d' ' -f1)"
              else
                printf -- "- %s (missing)\n" "$f"
              fi
            done
            echo
            echo "## npm scripts"
            if [ -f package.json ]; then
              node -e "const s=require('./package.json').scripts||{}; for (const k of Object.keys(s)) console.log('-',k+':',s[k])"
            fi
          } > .artifacts/STATE.md

      - name: Upload repo snapshot artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-snapshot-${{ github.sha }}
          path: .artifacts/
          if-no-files-found: error
          retention-days: 45

      # ---- Node setup / install (no cache to avoid lockfile requirement) ----
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18

      - name: Install dependencies
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi

      # ---- Generate site-data BEFORE build (scans /public/audio and /public/videos) ----
      - name: Generate media JSON
        run: |
          if [ -f scripts/generateMedia.cjs ]; then
            node scripts/generateMedia.cjs
          else
            echo "No generator script found - skipping."
          fi

      # With next.config.js { output: 'export' }, this creates ./out
      - name: Build (Next.js static export)
        run: npm run build

      - name: Verify build output
        run: test -d out

      # ---- Deploy to Azure Static Website container ($web) ----
      - name: Upload to Azure Static Website (no azcopy)
        uses: azure/cli@v2
        with:
          azcliversion: "2.61.0"
          inlineScript: |
            set -euo pipefail

            # 1) Do NOT use azcopy; stick to Python SDK path for consistency
            export AZURE_STORAGE_USE_AZCOPY=false

            # 2) Enable static website (idempotent; uses env creds)
            az storage blob service-properties update \
              --static-website \
              --index-document index.html \
              --404-document 404.html || true

            # 3) Upload changed files
            az storage blob upload-batch \
              --destination '$web' \
              --source ./out \
              --overwrite true

            # 4) Delete remote files that no longer exist locally
            tmp_local=$(mktemp)
            tmp_remote=$(mktemp)
            (cd out && find . -type f -print | sed 's#^\./##' | sort) > "$tmp_local"
            az storage blob list -c '$web' --query "[].name" -o tsv | sort > "$tmp_remote" || true
            comm -23 "$tmp_remote" "$tmp_local" | while IFS= read -r blob; do
              [ -z "$blob" ] && continue
              echo "Deleting obsolete blob: $blob"
              az storage blob delete -c '$web' -n "$blob" --only-show-errors || true
            done
            rm -f "$tmp_local" "$tmp_remote"

            # 5) Ensure correct Content-Types for common media (avoid application/octet-stream)
            fix_type () {
              local pattern="$1"; local ctype="$2"
              find out -type f -name "$pattern" -print0 | while IFS= read -r -d '' f; do
                blob="${f#out/}"
                echo "Setting Content-Type '$ctype' on: $blob"
                az storage blob update -c '$web' -n "$blob" --content-type "$ctype" --only-show-errors || true
              done
            }
            fix_type "*.mp4"  "video/mp4"
            fix_type "*.m4v"  "video/mp4"
            fix_type "*.webm" "video/webm"
            fix_type "*.ogv"  "video/ogg"
            fix_type "*.mp3"  "audio/mpeg"
            fix_type "*.m4a"  "audio/mp4"
            fix_type "*.ogg"  "audio/ogg"
            fix_type "*.opus" "audio/opus"
